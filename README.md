# Experiments

## Here we 'll discuss the details of files

## Naive-Bayes.ipynb
- Naive-Bayes Experiment with CountVectorizers
- Naive-Bayes Experiment with TF-IDF vectorizers

## Models on CountVectorizers and TF-IDF vectorizers.ipynb
- Logistic Regression on Count Vectorizer
- Logistic Regression on TFIDF
- Decision Tree on Count Vectorizers
- Decision Trees on TF-IDF
- Random Forest on Count Vectorizers
- Random Forest on TF-IDF
- AdaBoost on CountVectorizers
- Adaboost on TF-IDF
- Gradient Boosting on CountVectorizers
- XG- BOOST on COunt vectors
- XG-BOOST on TF-IDF

` All the experiments have undergone Hyper-parameter tuning using GridSearchCV`

### LSTM GRU experiments.ipynb - All RNN architectures
- LSTM
- BiLSTM
- GRU
- BiGRU 

## Pretrained-bert.ipynb for Pretrained-BERT model (Only Last Output Layer trainable BERT model weights fixed)

## BERT-Fine-tuned.ipynb for fine-tuning (All the Parameters Tuned)

## CNN-Based-Hybrid Experiments.ipynb
- fine-tuned BERT + 2D-CNN Experiment
- Fine-tuned BERT + 1D-CNN-BiLSTM experiment

## BERT LSTM hybrid Experiments
- Pretrained BERT BiLSTM
- Pretrained BERT BiGRU
- Fine-tuned BERT BiLSTM
- Fine-tuned BERT BiGRU
