{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer,PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29992, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet = pd.read_csv(\"train.csv\")\n",
    "df_tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweets', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anxious     8388\n",
       "Normal      7976\n",
       "Stressed    6840\n",
       "Lonely      6788\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting class Labels into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sending solidarity whoever doctor manage incre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need see hair amp beard gat book appointment b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next time meet someone new dont ask ask love</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise someone love give la senza gift box r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raise hand junhoes ocean lotion life rent free...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  labels\n",
       "0  sending solidarity whoever doctor manage incre...       2\n",
       "1  need see hair amp beard gat book appointment b...       0\n",
       "2      next time meet someone new dont ask ask love        1\n",
       "3  surprise someone love give la senza gift box r...       3\n",
       "4  raise hand junhoes ocean lotion life rent free...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {\n",
    "    \"Anxious\": 0,\n",
    "    \"Normal\": 1,\n",
    "    \"Stressed\": 2,\n",
    "    \"Lonely\": 3\n",
    "}\n",
    "\n",
    "df_tweet[\"labels\"] = df_tweet[\"labels\"].map(mapper)\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the text\n",
    "1. convert text to lowercase\n",
    "2. Tokenize the text\n",
    "3. Stem the text\n",
    "4. Regex based removal of (URL, Mentions and Hashtag)\n",
    "5. Remove the stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    ### Regex based cleaning\n",
    "    url = \"https?://([A-z0-9_\\.\\-%]+/)*[A-z0-9_\\.\\-%&=\\?]+\"\n",
    "    hashtags = \"#[A-z0-9_\\.\\-]+\"\n",
    "    mentions = \"@[A-z0-9_\\.\\-]+\"\n",
    "    text = re.sub(url,\"\",text)\n",
    "    text = re.sub(hashtags,\"\",text)\n",
    "    text = re.sub(mentions,\"\",text)\n",
    "    ### Tokenize the text \n",
    "    words = word_tokenize(text)\n",
    "        \n",
    "    ### Stem the words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    ### Stwopwords removal\n",
    "    sw = stopwords.words(\"english\")\n",
    "    words = [w for w in words if w not in sw]\n",
    "    \n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet_model = df_tweet.copy()\n",
    "df_tweet_model['tweets'] = df_tweet_model['tweets'].apply(process_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate features from text using countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the data into train and test \n",
    "X_train,X_test,y_train,y_test = train_test_split(df_tweet_model[['tweets']],df_tweet_model['labels'],\n",
    "                                                 train_size=0.75,random_state=2)\n",
    "\n",
    "### Transform data\n",
    "vc = CountVectorizer()\n",
    "X_train = vc.fit_transform(X_train['tweets'])\n",
    "X_train_bk = X_train.toarray()\n",
    "X_test = vc.transform(X_test[\"tweets\"])\n",
    "X_test_bk = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7498, 16529)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22494, 16529)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "lm = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "lm_grid = GridSearchCV(estimator=lm,param_grid=params,cv=5,scoring='balanced_accuracy', n_jobs=-1, verbose=10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6594062349486429\n",
      "Train confusion matrix:\n",
      "[[4115  394   75 1683]\n",
      " [ 163 5689   56  110]\n",
      " [  46  245 4825   31]\n",
      " [2238  274   44 2506]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      6267\n",
      "           1       0.86      0.95      0.90      6018\n",
      "           2       0.96      0.94      0.95      5147\n",
      "           3       0.58      0.50      0.53      5062\n",
      "\n",
      "    accuracy                           0.76     22494\n",
      "   macro avg       0.76      0.76      0.76     22494\n",
      "weighted avg       0.76      0.76      0.76     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1052  148   33  888]\n",
      " [  51 1831   27   49]\n",
      " [  16  126 1538   13]\n",
      " [1128   98   24  476]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.48      2121\n",
      "           1       0.83      0.94      0.88      1958\n",
      "           2       0.95      0.91      0.93      1693\n",
      "           3       0.33      0.28      0.30      1726\n",
      "\n",
      "    accuracy                           0.65      7498\n",
      "   macro avg       0.65      0.65      0.65      7498\n",
      "weighted avg       0.64      0.65      0.65      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lm_grid.best_score_)\n",
    "lm =lm_grid.best_estimator_\n",
    "\n",
    "\n",
    "### Evaluate Model\n",
    "def evaluate_model(model,X,y,X_test,y_test):\n",
    "    y_train_pred = model.predict(X)\n",
    "    train_cf = confusion_matrix(y,y_train_pred)\n",
    "    print(\"Train confusion matrix:\")\n",
    "    print(train_cf)\n",
    "    print(\"Train report:\")\n",
    "    print(classification_report(y,y_train_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_cf = confusion_matrix(y_test,y_test_pred)\n",
    "    print(\"Test confusion matrix:\")\n",
    "    print(test_cf)\n",
    "    print(\"Test report:\")\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "evaluate_model(lm,X_train,y_train,X_test,y_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The test score is very low hence we will try Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"min_samples_split\": [20,50,100,500],\n",
    "    \"min_samples_leaf\": [20,100,500],\n",
    "    \"max_depth\": [10,20,30],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "### grid search\n",
    "dt_grid = GridSearchCV(estimator=dt,param_grid=params,cv=5,n_jobs=-1,verbose=10,scoring=\"balanced_accuracy\").fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      "[[4528  597   91 1051]\n",
      " [ 194 5547   88  189]\n",
      " [  83  439 4575   50]\n",
      " [3292  421   63 1286]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63      6267\n",
      "           1       0.79      0.92      0.85      6018\n",
      "           2       0.95      0.89      0.92      5147\n",
      "           3       0.50      0.25      0.34      5062\n",
      "\n",
      "    accuracy                           0.71     22494\n",
      "   macro avg       0.70      0.70      0.68     22494\n",
      "weighted avg       0.70      0.71      0.69     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1449  195   31  446]\n",
      " [  58 1801   37   62]\n",
      " [  33  162 1485   13]\n",
      " [1229  136   22  339]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59      2121\n",
      "           1       0.79      0.92      0.85      1958\n",
      "           2       0.94      0.88      0.91      1693\n",
      "           3       0.39      0.20      0.26      1726\n",
      "\n",
      "    accuracy                           0.68      7498\n",
      "   macro avg       0.66      0.67      0.65      7498\n",
      "weighted avg       0.66      0.68      0.65      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = dt_grid.best_estimator_\n",
    "\n",
    "dt = dt.fit(X_train,y_train)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "evaluate_model(dt,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model fit is good but The test performance for lonely is very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "    \"min_samples_split\": [20,50,100],\n",
    "    \"min_samples_leaf\": [20,50,100],\n",
    "    \"max_features\": [10,100,1000],\n",
    "    \"max_depth\": [10,20,30],\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687449753528389"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      "[[4462  589   88 1128]\n",
      " [ 295 5514   79  130]\n",
      " [ 100  506 4530   11]\n",
      " [3167  461   65 1369]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.62      6267\n",
      "           1       0.78      0.92      0.84      6018\n",
      "           2       0.95      0.88      0.91      5147\n",
      "           3       0.52      0.27      0.36      5062\n",
      "\n",
      "    accuracy                           0.71     22494\n",
      "   macro avg       0.70      0.69      0.68     22494\n",
      "weighted avg       0.70      0.71      0.69     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1411  190   37  483]\n",
      " [  77 1801   29   51]\n",
      " [  36  186 1470    1]\n",
      " [1198  144   24  360]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.58      2121\n",
      "           1       0.78      0.92      0.84      1958\n",
      "           2       0.94      0.87      0.90      1693\n",
      "           3       0.40      0.21      0.27      1726\n",
      "\n",
      "    accuracy                           0.67      7498\n",
      "   macro avg       0.66      0.67      0.65      7498\n",
      "weighted avg       0.65      0.67      0.65      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = rf_grid.best_estimator_\n",
    "\n",
    "evaluate_model(rf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "ad = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "ad_grid = GridSearchCV(estimator=ad, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712538139358134"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      "[[3941  953   66 1307]\n",
      " [ 145 5612   74  187]\n",
      " [  88  487 4541   31]\n",
      " [3027  660   39 1336]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      6267\n",
      "           1       0.73      0.93      0.82      6018\n",
      "           2       0.96      0.88      0.92      5147\n",
      "           3       0.47      0.26      0.34      5062\n",
      "\n",
      "    accuracy                           0.69     22494\n",
      "   macro avg       0.68      0.68      0.67     22494\n",
      "weighted avg       0.67      0.69      0.67     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1342  290   30  459]\n",
      " [  32 1831   29   66]\n",
      " [  27  170 1490    6]\n",
      " [1076  205   18  427]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58      2121\n",
      "           1       0.73      0.94      0.82      1958\n",
      "           2       0.95      0.88      0.91      1693\n",
      "           3       0.45      0.25      0.32      1726\n",
      "\n",
      "    accuracy                           0.68      7498\n",
      "   macro avg       0.67      0.67      0.66      7498\n",
      "weighted avg       0.66      0.68      0.66      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ad = ad_grid.best_estimator_\n",
    "evaluate_model(ad,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state=1)\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    \"max_depth\": [3,5],\n",
    "    \"n_estimators\": [50,100]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(estimator=gb, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = gb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6878818029441043"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 761,  196,   38, 1126],\n",
       "       [  15, 1823,   37,   83],\n",
       "       [   3,  114, 1565,   11],\n",
       "       [ 584,  146,   27,  969]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = gb.predict(X_test)\n",
    "cf = confusion_matrix(y_test,y_test_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.36      0.44      2121\n",
      "           1       0.80      0.93      0.86      1958\n",
      "           2       0.94      0.92      0.93      1693\n",
      "           3       0.44      0.56      0.50      1726\n",
      "\n",
      "    accuracy                           0.68      7498\n",
      "   macro avg       0.68      0.69      0.68      7498\n",
      "weighted avg       0.68      0.68      0.67      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:45:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train confusion matrix:\n",
      "[[4409  416   54 1388]\n",
      " [ 153 5635   68  162]\n",
      " [  24  245 4862   16]\n",
      " [2728  286   33 2015]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.65      6267\n",
      "           1       0.86      0.94      0.89      6018\n",
      "           2       0.97      0.94      0.96      5147\n",
      "           3       0.56      0.40      0.47      5062\n",
      "\n",
      "    accuracy                           0.75     22494\n",
      "   macro avg       0.75      0.75      0.74     22494\n",
      "weighted avg       0.75      0.75      0.74     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1247  142   28  704]\n",
      " [  50 1819   30   59]\n",
      " [  16  105 1562   10]\n",
      " [1201  105   20  400]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.54      2121\n",
      "           1       0.84      0.93      0.88      1958\n",
      "           2       0.95      0.92      0.94      1693\n",
      "           3       0.34      0.23      0.28      1726\n",
      "\n",
      "    accuracy                           0.67      7498\n",
      "   macro avg       0.66      0.67      0.66      7498\n",
      "weighted avg       0.65      0.67      0.66      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg = XGBClassifier()\n",
    "\n",
    "xg.fit(X_train,y_train)\n",
    "#y_train_pred = xg.predict(X_train)\n",
    "#print(y_train_pred)\n",
    "#y_test_pred = xg.predict(X_test)\n",
    "#print(confusion_matrix(y_train,y_train_pred))\n",
    "evaluate_model(xg,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still confusion between class 1 and class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing all the best model on cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression LogisticRegression(C=0.1)\n",
      "Decision Tree DecisionTreeClassifier(max_depth=20, min_samples_leaf=20, min_samples_split=20,\n",
      "                       random_state=1)\n",
      "Random Forest RandomForestClassifier(max_depth=30, max_features=1000, min_samples_leaf=20,\n",
      "                       min_samples_split=20, random_state=1)\n",
      "Ada Boost AdaBoostClassifier(learning_rate=0.3, random_state=1)\n",
      "Gradient Boostin GradientBoostingClassifier(learning_rate=0.3, n_estimators=50, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\", lm_grid.best_estimator_)\n",
    "print(\"Decision Tree\", dt_grid.best_estimator_)\n",
    "print(\"Random Forest\", rf_grid.best_estimator_)\n",
    "print(\"Ada Boost\", ad_grid.best_estimator_)\n",
    "print(\"Gradient Boostin\", gb_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us see the TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29992, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vc = TfidfVectorizer()\n",
    "\n",
    "df_tweet_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_tweet_model is preprocessed text hance we can use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df_tweet_model,train_size=0.75,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vc.fit_transform(df_train[\"tweets\"])\n",
    "X_test_tf = vc.transform(df_test[\"tweets\"])\n",
    "y_train = df_train[\"labels\"]\n",
    "y_test = df_test[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raoms_y121yee\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6452736654202411\n",
      "logistic Regression + tfidf\n",
      "Train confusion matrix:\n",
      "[[4397  333   63 1474]\n",
      " [ 169 5721   51   77]\n",
      " [  47  254 4833   13]\n",
      " [2365  258   41 2398]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.70      0.66      6267\n",
      "           1       0.87      0.95      0.91      6018\n",
      "           2       0.97      0.94      0.95      5147\n",
      "           3       0.61      0.47      0.53      5062\n",
      "\n",
      "    accuracy                           0.77     22494\n",
      "   macro avg       0.77      0.77      0.76     22494\n",
      "weighted avg       0.77      0.77      0.77     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1081  158   30  852]\n",
      " [  66 1813   31   48]\n",
      " [  18  122 1542   11]\n",
      " [1198  101   20  407]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.51      0.48      2121\n",
      "           1       0.83      0.93      0.87      1958\n",
      "           2       0.95      0.91      0.93      1693\n",
      "           3       0.31      0.24      0.27      1726\n",
      "\n",
      "    accuracy                           0.65      7498\n",
      "   macro avg       0.64      0.65      0.64      7498\n",
      "weighted avg       0.63      0.65      0.64      7498\n",
      "\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Decision Tree + tfidf\n",
      "Train confusion matrix:\n",
      "[[4183  558   81 1445]\n",
      " [ 385 5391   73  169]\n",
      " [ 111  438 4525   73]\n",
      " [2799  447   55 1761]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61      6267\n",
      "           1       0.79      0.90      0.84      6018\n",
      "           2       0.96      0.88      0.92      5147\n",
      "           3       0.51      0.35      0.41      5062\n",
      "\n",
      "    accuracy                           0.71     22494\n",
      "   macro avg       0.70      0.70      0.69     22494\n",
      "weighted avg       0.70      0.71      0.70     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1276  187   27  631]\n",
      " [ 113 1769   28   48]\n",
      " [  33  166 1471   23]\n",
      " [1086  147   20  473]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55      2121\n",
      "           1       0.78      0.90      0.84      1958\n",
      "           2       0.95      0.87      0.91      1693\n",
      "           3       0.40      0.27      0.33      1726\n",
      "\n",
      "    accuracy                           0.67      7498\n",
      "   macro avg       0.66      0.66      0.66      7498\n",
      "weighted avg       0.66      0.67      0.65      7498\n",
      "\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Random Forest + tfidf\n",
      "Train confusion matrix:\n",
      "[[4526  607   92 1042]\n",
      " [ 266 5541   84  127]\n",
      " [  84  500 4548   15]\n",
      " [3127  474   67 1394]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.63      6267\n",
      "           1       0.78      0.92      0.84      6018\n",
      "           2       0.95      0.88      0.92      5147\n",
      "           3       0.54      0.28      0.36      5062\n",
      "\n",
      "    accuracy                           0.71     22494\n",
      "   macro avg       0.71      0.70      0.69     22494\n",
      "weighted avg       0.70      0.71      0.69     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1386  196   37  502]\n",
      " [  86 1807   34   31]\n",
      " [  34  186 1471    2]\n",
      " [1223  148   27  328]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57      2121\n",
      "           1       0.77      0.92      0.84      1958\n",
      "           2       0.94      0.87      0.90      1693\n",
      "           3       0.38      0.19      0.25      1726\n",
      "\n",
      "    accuracy                           0.67      7498\n",
      "   macro avg       0.65      0.66      0.64      7498\n",
      "weighted avg       0.64      0.67      0.64      7498\n",
      "\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Adaboost + tfidf\n",
      "Train confusion matrix:\n",
      "[[3971  953   63 1280]\n",
      " [ 145 5612   74  187]\n",
      " [  96  511 4511   29]\n",
      " [3057  660   36 1309]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      6267\n",
      "           1       0.73      0.93      0.82      6018\n",
      "           2       0.96      0.88      0.92      5147\n",
      "           3       0.47      0.26      0.33      5062\n",
      "\n",
      "    accuracy                           0.68     22494\n",
      "   macro avg       0.68      0.68      0.66     22494\n",
      "weighted avg       0.67      0.68      0.67     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[1359  290   26  446]\n",
      " [  32 1831   29   66]\n",
      " [  32  179 1476    6]\n",
      " [1089  205   15  417]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.64      0.59      2121\n",
      "           1       0.73      0.94      0.82      1958\n",
      "           2       0.95      0.87      0.91      1693\n",
      "           3       0.45      0.24      0.31      1726\n",
      "\n",
      "    accuracy                           0.68      7498\n",
      "   macro avg       0.67      0.67      0.66      7498\n",
      "weighted avg       0.66      0.68      0.66      7498\n",
      "\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "GBM + tfidf\n",
      "Train confusion matrix:\n",
      "[[2672  613   67 2915]\n",
      " [  77 5624   69  248]\n",
      " [  16  257 4856   18]\n",
      " [1297  408   58 3299]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.43      0.52      6267\n",
      "           1       0.81      0.93      0.87      6018\n",
      "           2       0.96      0.94      0.95      5147\n",
      "           3       0.51      0.65      0.57      5062\n",
      "\n",
      "    accuracy                           0.73     22494\n",
      "   macro avg       0.74      0.74      0.73     22494\n",
      "weighted avg       0.74      0.73      0.72     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[ 734  195   37 1155]\n",
      " [  23 1828   32   75]\n",
      " [   7  109 1568    9]\n",
      " [ 624  133   23  946]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.35      0.42      2121\n",
      "           1       0.81      0.93      0.87      1958\n",
      "           2       0.94      0.93      0.94      1693\n",
      "           3       0.43      0.55      0.48      1726\n",
      "\n",
      "    accuracy                           0.68      7498\n",
      "   macro avg       0.68      0.69      0.68      7498\n",
      "weighted avg       0.67      0.68      0.67      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Splitting the data into train and test \n",
    "X_train,X_test,y_train,y_test = train_test_split(df_tweet_model[['tweets']],df_tweet_model['labels'],\n",
    "                                                 train_size=0.75,random_state=2)\n",
    "\n",
    "### Transform data\n",
    "vc = TfidfVectorizer()\n",
    "X_train = vc.fit_transform(X_train['tweets'])\n",
    "X_train_bk = X_train.toarray()\n",
    "X_test = vc.transform(X_test[\"tweets\"])\n",
    "X_test_bk = X_test.toarray()\n",
    "\n",
    "X_test_bk.shape\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "### Logistic Regression model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "lm = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "lm_grid = GridSearchCV(estimator=lm,param_grid=params,cv=5,scoring='balanced_accuracy', n_jobs=-1, verbose=10).fit(X_train,y_train)\n",
    "\n",
    "print(lm_grid.best_score_)\n",
    "lm =lm_grid.best_estimator_\n",
    "\n",
    "\n",
    "### Evaluate Model\n",
    "def evaluate_model(model,X,y,X_test,y_test):\n",
    "    y_train_pred = model.predict(X)\n",
    "    train_cf = confusion_matrix(y,y_train_pred)\n",
    "    print(\"Train confusion matrix:\")\n",
    "    print(train_cf)\n",
    "    print(\"Train report:\")\n",
    "    print(classification_report(y,y_train_pred))\n",
    "    \n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_cf = confusion_matrix(y_test,y_test_pred)\n",
    "    print(\"Test confusion matrix:\")\n",
    "    print(test_cf)\n",
    "    print(\"Test report:\")\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"logistic Regression + tfidf\")    \n",
    "evaluate_model(lm,X_train,y_train,X_test,y_test)\n",
    "    \n",
    "\n",
    "\n",
    "### The test score is very low hence we will try Decision Tree\n",
    "\n",
    "params = {\n",
    "    \"min_samples_split\": [20,50,100,500],\n",
    "    \"min_samples_leaf\": [20,100,500],\n",
    "    \"max_depth\": [10,20,30],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "### grid search\n",
    "dt_grid = GridSearchCV(estimator=dt,param_grid=params,cv=5,n_jobs=-1,verbose=10,scoring=\"balanced_accuracy\").fit(X_train,y_train)\n",
    "\n",
    "\n",
    "dt = dt_grid.best_estimator_\n",
    "\n",
    "dt = dt.fit(X_train,y_train)\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree + tfidf\") \n",
    "evaluate_model(dt,X_train,y_train,X_test,y_test)\n",
    "\n",
    "### The model fit is good but The test performance for lonely is very low. \n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "params = {\n",
    "    \"min_samples_split\": [20,50,100],\n",
    "    \"min_samples_leaf\": [20,50,100],\n",
    "    \"max_features\": [10,100,1000],\n",
    "    \"max_depth\": [10,20,30],\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)\n",
    "\n",
    "rf_grid.best_score_\n",
    "\n",
    "rf = rf_grid.best_estimator_\n",
    "\n",
    "print(\"Random Forest + tfidf\") \n",
    "evaluate_model(rf,X_train,y_train,X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "ad = AdaBoostClassifier(random_state=1)\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "ad_grid = GridSearchCV(estimator=ad, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)\n",
    "\n",
    "ad_grid.best_score_\n",
    "\n",
    "ad = ad_grid.best_estimator_\n",
    "\n",
    "print(\"Adaboost + tfidf\") \n",
    "evaluate_model(ad,X_train,y_train,X_test,y_test)\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=1)\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    \"max_depth\": [3,5],\n",
    "    \"n_estimators\": [50,100]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(estimator=gb, param_grid=params, cv=5, n_jobs=-1, \n",
    "                  scoring=\"balanced_accuracy\", verbose=10).fit(X_train,y_train)\n",
    "\n",
    "gb = gb_grid.best_estimator_\n",
    "\n",
    "gb_grid.best_score_\n",
    "\n",
    "\n",
    "\n",
    "y_test_pred = gb.predict(X_test)\n",
    "cf = confusion_matrix(y_test,y_test_pred)\n",
    "cf\n",
    "\n",
    "print(\"GBM + tfidf\") \n",
    "evaluate_model(gb,X_train,y_train,X_test,y_test)\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:18:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train confusion matrix:\n",
      "[[3723  333   40 2171]\n",
      " [ 145 5703   40  130]\n",
      " [  23  224 4887   13]\n",
      " [1828  231   26 2977]]\n",
      "Train report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62      6267\n",
      "           1       0.88      0.95      0.91      6018\n",
      "           2       0.98      0.95      0.96      5147\n",
      "           3       0.56      0.59      0.58      5062\n",
      "\n",
      "    accuracy                           0.77     22494\n",
      "   macro avg       0.77      0.77      0.77     22494\n",
      "weighted avg       0.77      0.77      0.77     22494\n",
      "\n",
      "Test confusion matrix:\n",
      "[[ 916  132   27 1046]\n",
      " [  68 1826   22   42]\n",
      " [  16  104 1563   10]\n",
      " [ 934   90   18  684]]\n",
      "Test report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.43      0.45      2121\n",
      "           1       0.85      0.93      0.89      1958\n",
      "           2       0.96      0.92      0.94      1693\n",
      "           3       0.38      0.40      0.39      1726\n",
      "\n",
      "    accuracy                           0.67      7498\n",
      "   macro avg       0.67      0.67      0.67      7498\n",
      "weighted avg       0.66      0.67      0.66      7498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg.fit(X_train,y_train)\n",
    "#y_train_pred = xg.predict(X_train)\n",
    "#print(y_train_pred)\n",
    "#y_test_pred = xg.predict(X_test)\n",
    "#print(confusion_matrix(y_train,y_train_pred))\n",
    "evaluate_model(xg,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression LogisticRegression(C=1)\n",
      "Decision Tree DecisionTreeClassifier(max_depth=20, min_samples_leaf=20, min_samples_split=500,\n",
      "                       random_state=1)\n",
      "Random Forest RandomForestClassifier(max_depth=30, max_features=1000, min_samples_leaf=20,\n",
      "                       min_samples_split=100, random_state=1)\n",
      "Ada Boost AdaBoostClassifier(learning_rate=0.3, random_state=1)\n",
      "Gradient Boostin GradientBoostingClassifier(learning_rate=0.3, n_estimators=50, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression\", lm_grid.best_estimator_)\n",
    "print(\"Decision Tree\", dt_grid.best_estimator_)\n",
    "print(\"Random Forest\", rf_grid.best_estimator_)\n",
    "print(\"Ada Boost\", ad_grid.best_estimator_)\n",
    "print(\"Gradient Boostin\", gb_grid.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
